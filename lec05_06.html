<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <title>High Performance Computing Exam â€“ Lectures 5 & 6</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Cairo:wght@400;600;700&family=Inter:wght@400;600;700&family=JetBrains+Mono:wght@400&display=swap"
        rel="stylesheet">
    <style>
        :root {
            --primary: #38bdf8;
            --secondary: #818cf8;
            --accent: #c084fc;
            --background: #0f172a;
            --surface: #1e293b;
            --text: #f8fafc;
            --text-muted: #94a3b8;
            --success: #4ade80;
            --error: #f87171;
            --warning: #fbbf24;
        }

        * {
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', system-ui, -apple-system, sans-serif;
            background-color: var(--background);
            background-image:
                radial-gradient(at 0% 0%, rgba(56, 189, 248, 0.1) 0px, transparent 50%),
                radial-gradient(at 100% 0%, rgba(139, 92, 246, 0.1) 0px, transparent 50%),
                radial-gradient(at 100% 100%, rgba(192, 132, 252, 0.05) 0px, transparent 50%);
            background-attachment: fixed;
            color: var(--text);
            line-height: 1.6;
            margin: 0;
            padding: 40px 20px;
            min-height: 100vh;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
        }

        header {
            text-align: center;
            margin-bottom: 60px;
            padding-bottom: 40px;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            position: relative;
        }

        header::after {
            content: '';
            position: absolute;
            bottom: -1px;
            left: 50%;
            transform: translateX(-50%);
            width: 200px;
            height: 1px;
            background: linear-gradient(90deg, transparent, var(--primary), transparent);
        }

        header h1 {
            font-size: 3.5rem;
            font-weight: 800;
            background: linear-gradient(to right, #38bdf8, #818cf8, #c084fc);
            -webkit-background-clip: text;
            background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 15px;
            letter-spacing: -1px;
            text-shadow: 0 0 40px rgba(56, 189, 248, 0.2);
        }

        header h2 {
            font-size: 1.5rem;
            color: var(--text-muted);
            font-weight: 400;
            margin-top: 10px;
        }

        .exam-info {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
            gap: 20px;
            margin-bottom: 50px;
        }

        .exam-info h3 {
            display: none;
        }

        /* We will hide the old header inside */
        .info-grid {
            display: contents;
        }

        .info-item {
            background: rgba(30, 41, 59, 0.4);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.05);
            padding: 20px;
            border-radius: 16px;
            transition: all 0.3s ease;
            text-align: center;
        }

        .info-item:hover {
            transform: translateY(-5px) scale(1.02);
            background: rgba(30, 41, 59, 0.6);
            border-color: rgba(56, 189, 248, 0.3);
            box-shadow: 0 10px 30px -10px rgba(56, 189, 248, 0.15);
        }

        .info-item strong {
            display: block;
            color: var(--primary);
            font-size: 0.85rem;
            text-transform: uppercase;
            letter-spacing: 1.5px;
            margin-bottom: 8px;
        }

        /* Section Styling */
        .section {
            position: relative;
            padding: 30px 0;
            margin-bottom: 60px;
            background: transparent;
            border: none;
            box-shadow: none;
            backdrop-filter: none;
        }

        .section-header {
            font-size: 2.2rem;
            font-weight: 700;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 15px;
            padding-bottom: 15px;
            border-bottom: 2px solid;
            border-image: linear-gradient(to right, currentColor, transparent) 1;
            text-align: left;
            /* Override previous center alignment if any */
        }

        .section-header:nth-of-type(1) {
            color: var(--primary);
        }

        .section-header:nth-of-type(2) {
            color: var(--secondary);
        }

        .section-header:nth-of-type(3) {
            color: var(--success);
        }

        .section-header:nth-of-type(4) {
            color: var(--warning);
        }


        /* Question Styling */
        .question {
            background: rgba(17, 24, 39, 0.7);
            border: 1px solid rgba(255, 255, 255, 0.08);
            backdrop-filter: blur(16px);
            border-radius: 24px;
            padding: 35px;
            margin-bottom: 40px;
            transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
            position: relative;
            overflow: hidden;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
        }

        .question::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 4px;
            background: linear-gradient(90deg, var(--primary), var(--secondary), transparent);
            opacity: 0.8;
        }

        .question:hover {
            transform: translateY(-4px);
            background: rgba(30, 41, 59, 0.8);
            box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.5);
            border-color: rgba(56, 189, 248, 0.3);
        }

        .question-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px solid rgba(255, 255, 255, 0.05);
        }

        .question-number {
            font-family: 'JetBrains Mono', monospace;
            color: var(--primary);
            font-size: 1.1rem;
            background: rgba(56, 189, 248, 0.1);
            padding: 8px 16px;
            border-radius: 8px;
            border: 1px solid rgba(56, 189, 248, 0.2);
            font-weight: 700;
        }

        .question-marks {
            font-size: 0.95rem;
            color: var(--text-muted);
            font-weight: 600;
            background: rgba(255, 255, 255, 0.05);
            padding: 6px 12px;
            border-radius: 20px;
        }

        .question-content {
            font-size: 1.15rem;
            color: #e2e8f0;
            margin-bottom: 30px;
            line-height: 1.8;
        }

        /* Code Block */
        .code-block,
        pre,
        code {
            font-family: 'JetBrains Mono', monospace;
        }

        .question pre {
            background: #09090b;
            padding: 25px;
            border-radius: 12px;
            border: 1px solid #27272a;
            font-size: 0.95rem;
            margin: 25px 0;
            overflow-x: auto;
            position: relative;
            box-shadow: inset 0 0 40px rgba(0, 0, 0, 0.3);
            color: #e2e8f0;
        }

        code {
            background: rgba(255, 255, 255, 0.1);
            padding: 2px 6px;
            border-radius: 4px;
            color: #38bdf8;
            font-size: 0.9em;
        }

        /* New QA Structure for Interleaved Answers */
        .qa-container {
            margin-top: 20px;
        }

        .qa-pair {
            margin-bottom: 25px;
            background: rgba(15, 23, 42, 0.3);
            border: 1px solid rgba(255, 255, 255, 0.05);
            border-radius: 12px;
            overflow: hidden;
        }

        .qa-question {
            padding: 15px 20px;
            font-size: 1.05rem;
            color: #fff;
            background: rgba(56, 189, 248, 0.05);
            border-bottom: 1px solid rgba(255, 255, 255, 0.05);
            font-weight: 600;
        }

        .qa-answer-block {
            display: grid;
            grid-template-columns: 1fr 1fr;
            /* English | Arabic */
            gap: 0;
        }

        .qa-english {
            padding: 20px;
            border-right: 1px solid rgba(255, 255, 255, 0.05);
            background: rgba(2, 6, 23, 0.2);
        }

        .qa-arabic {
            padding: 20px;
            direction: rtl;
            text-align: right;
            font-family: 'Cairo', sans-serif;
            background: rgba(30, 41, 59, 0.2);
        }

        /* Mobile */
        @media (max-width: 900px) {
            .qa-answer-block {
                grid-template-columns: 1fr;
            }

            .qa-english {
                border-right: none;
                border-bottom: 1px solid rgba(255, 255, 255, 0.05);
            }
        }

        .label-eng {
            color: var(--primary);
            font-size: 0.8rem;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 10px;
            font-weight: bold;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .label-ar {
            color: var(--success);
            font-size: 0.9rem;
            margin-bottom: 10px;
            font-weight: bold;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        /* Arabic Styles Refined */
        .arabic-text,
        .question-explanation,
        .egyptian-explanation {
            font-family: 'Cairo', sans-serif;
            direction: rtl;
            text-align: right;
            line-height: 1.8;
        }

        .egyptian-explanation {
            background: linear-gradient(to right, rgba(34, 197, 94, 0.05), rgba(34, 197, 94, 0.1));
            border-right: 4px solid var(--success);
            padding: 25px;
            border-radius: 12px;
            margin-top: 0;
            color: #f1f5f9;
            font-size: 1.15rem;
            height: 100%;
        }

        .egyptian-explanation h4 {
            color: var(--success);
            margin-bottom: 15px;
            font-size: 1.2rem;
            font-weight: 700;
        }

        .highlight {
            background: rgba(56, 189, 248, 0.15);
            color: var(--primary);
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.9em;
        }

        footer {
            text-align: center;
            padding: 60px 0;
            color: var(--text-muted);
            border-top: 1px solid rgba(255, 255, 255, 0.05);
            margin-top: 60px;
        }

        .small {
            font-size: 0.85em;
            color: var(--text-muted);
        }
    </style>
</head>

<body>

    <!-- University / Course Header -->
    <h1>High Performance Computing</h1>
    <div class="meta">
        <div>Course: High Performance Computing (Parallel Execution & Memory Systems)</div>
        <div>Topic: Lectures 5 &amp; 6 â€“ Modern Multi-Core Processors, SIMD &amp; Memory</div>
        <div>Total Marks: 50 &nbsp;|&nbsp; Suggested Time: 120 minutes</div>
    </div>

    <div class="section-header">SECTION 1: CUDA / PARALLEL PROGRAMMING (20 marks)</div>

    <!-- Q1 -->
    <!-- Q1 -->
    <div class="question">
        <div class="question-header">
            <span class="question-number">Question 1</span>
            <span class="question-marks">5 Marks</span>
        </div>
        <div class="question-content">
            <h3>Understanding Parallel Execution Models</h3>
            <p>Consider the following C function that computes <code>sin(x)</code> using a Taylor expansion for an array
                of
                <code>N</code> elements:
            </p>
            <pre><code>void sinx(int N, int terms, float* x, float* result)
{
    for (int i = 0; i &lt; N; i++)
    {
        float value = x[i];
        float numer = x[i] * x[i] * x[i];
        int   denom = 6; // 3!
        int   sign  = -1;

        for (int j = 1; j &lt;= terms; j++)
        {
            value += sign * numer / denom;
            numer *= x[i] * x[i];
            denom *= (2*j+2) * (2*j+3);
            sign  *= -1;
        }
        result[i] = value;
    }
}</code></pre>

            <div class="qa-container">
                <!-- Part A -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (a) Identify which loop iterations are data-independent and can be parallelized. (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>The outer loop over <code>i</code> is data-independent and can be parallelized, because
                                each iteration reads a distinct <code>x[i]</code> and writes a distinct
                                <code>result[i]</code> without cross-iteration dependencies; the inner loop over
                                <code>j</code> is sequential because each iteration depends on the updated
                                <code>value</code>, <code>numer</code>, and <code>denom</code> from the previous
                                iteration.
                            </p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„Ù„ÙˆØ¨ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø§Ù„Ù„ÙŠ Ø¨ØªÙ„Ù Ø¹Ù„Ù‰ <code>i</code> Ø¯ÙŠ "Ø³Ø§Ù„ÙƒØ©" (independent). ÙŠØ¹Ù†ÙŠ ÙƒÙ„ Ø¹Ù†ØµØ±
                                <code>x[i]</code> Ø¹Ø§ÙŠØ´ ÙÙŠ Ø¯Ù†ÙŠØ§ Ù„ÙˆØ­Ø¯Ù‡ ÙˆØ¨ÙŠØªØ­Ø³Ø¨ Ù„ÙˆØ­Ø¯Ù‡ Ù…Ù† ØºÙŠØ± Ù…Ø§ ÙŠØ³Ø£Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù„ÙŠ Ø¬Ù†Ø¨Ù‡. Ø¹Ø´Ø§Ù†
                                ÙƒØ¯Ù‡ Ù†Ù‚Ø¯Ø± Ù†Ø´ØºÙ„Ù‡Ù… ÙƒÙ„Ù‡Ù… Ù…Ø¹ Ø¨Ø¹Ø¶ ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª.
                            </p>
                        </div>
                    </div>
                </div>

                <!-- Part B -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (b) Explain why this program may run about 25% slower on a dual-core processor with simpler
                        cores than on a single, more complex core when compiled as-is (without explicit parallelism). (2
                        marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>In the â€œCPU: Multi-Core Eraâ€ model, the chip replaces a single complex core with two
                                simpler cores, each about 25% slower; since the program expresses no parallelism, the
                                compiled code runs as a single thread on only one simpler core, so performance becomes
                                roughly <code>1 Ã— 0.75</code> of the original, i.e., about 25% slower despite having two
                                cores available.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ù„ÙŠÙ‡ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø£Ø¨Ø·Ø£ØŸ Ø¹Ø´Ø§Ù† Ø§Ø­Ù†Ø§ ÙƒÙ†Ø§ Ø´ØºØ§Ù„ÙŠÙ† Ø¨Ù†ÙˆØ§Ø© ÙˆØ§Ø­Ø¯Ø© "Ø¹Ø¶Ù„Ø§ØªÙ‡Ø§ Ù…ÙØªÙˆÙ„Ø©" (Complex Core). Ù„Ù…Ø§
                                Ø¨Ø¯Ù„Ù†Ø§Ù‡Ø§ Ø¨Ù€ "Ø§ØªÙ†ÙŠÙ† Ø¹Ù…Ø§Ù„ Ø¹Ù„Ù‰ Ù‚Ø¯Ù‡Ù…" (Simpler Cores)ØŒ ÙˆØ§Ù„ÙƒÙˆØ¯ Ø¨ØªØ§Ø¹Ù†Ø§ Ù…Ø´ ÙØ§Ù‡Ù… ÙŠØ¹Ù†ÙŠ Ø¥ÙŠÙ‡ ØªÙˆØ§Ø²ÙŠØŒ
                                ÙÙ‡Ùˆ ÙØ¶Ù„ Ø´ØºØ§Ù„ Ø¹Ù„Ù‰ Ø¹Ø§Ù…Ù„ ÙˆØ§Ø­Ø¯ Ø¨Ø³ Ù…Ù†Ù‡Ù…. ÙØ·Ø¨ÙŠØ¹ÙŠ Ø§Ù„Ø¥Ù†Ø¬Ø§Ø² ÙŠÙ‚Ù„ Ù„Ø£Ù† Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø£Ø¶Ø¹Ù Ø¨Ù€ 25%.
                            </p>
                        </div>
                    </div>
                </div>

                <!-- Part C -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (c) Suggest a high-level language construct or annotation that exposes the available parallelism
                        in this function to a compiler. (1 mark)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>A data-parallel construct such as a <code>forall</code> loop over <code>i</code> (or
                                equivalently a parallel loop pragma, e.g. OpenMP <code>#pragma omp parallel for</code>)
                                can be used to declare that the iterations are independent, enabling the compiler to
                                automatically generate parallel threaded or vectorized code.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„Ø­Ù„ Ø¥Ù†Ù†Ø§ "Ù†ÙØªØ­ Ø¹ÙŠÙ†" Ø§Ù„ÙƒÙˆØ¯. Ù†Ø³ØªØ®Ø¯Ù… <code>forall</code> Ø£Ùˆ <code>OpenMP</code> Ø¹Ø´Ø§Ù† Ù†Ù‚ÙˆÙ„
                                Ù„Ù„Ù€ Compiler: "ÙŠØ§ Ø¨Ø´Ù…Ù‡Ù†Ø¯Ø³ØŒ Ø§Ù„Ù„ÙØ§Øª Ø¯ÙŠ Ù…Ù„Ù‡Ø§Ø´ Ø¯Ø¹ÙˆØ© Ø¨Ø¨Ø¹Ø¶ØŒ ÙˆØ²Ø¹ Ø§Ù„Ø´ØºÙ„ Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ø±Ø¬Ø§Ù„Ø© Ø§Ù„Ù„ÙŠ
                                Ø¹Ù†Ø¯Ùƒ".</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="reference small" style="margin-top: 20px;">
                ğŸ“ Reference: Lecture_5-and-6.pdf â€“ â€œExample program: sinxâ€, â€œCPU: Multi-Core Eraâ€, and â€œData-parallel
                expression (forall)â€.
            </div>
        </div>
    </div>

    <!-- Q2 -->
    <!-- Q2 -->
    <div class="question">
        <div class="question-header">
            <span class="question-number">Question 2</span>
            <span class="question-marks">5 Marks</span>
        </div>
        <div class="question-content">
            <h3>SIMD Programming with AVX Intrinsics</h3>
            <p>Now consider a vectorized version of <code>sinx</code> that processes 8 elements at a time using AVX
                intrinsics:</p>
            <pre><code>#include &lt;immintrin.h&gt;

void sinx_vec(int N, int terms, float* x, float* result)
{
    for (int i = 0; i &lt; N; i += 8)
    {
        __m256 origx = _mm256_load_ps(&x[i]);
        __m256 value = origx;
        __m256 numer = _mm256_mul_ps(origx,
                           _mm256_mul_ps(origx, origx));
        __m256 denom = _mm256_broadcast_ss((float*)&6); // 3!

        int sign = -1;
        for (int j = 1; j &lt;= terms; j++)
        {
            __m256 tmp = _mm256_div_ps(
                _mm256_mul_ps(_mm256_set1_ps((float)sign), numer),
                denom);
            value = _mm256_add_ps(value, tmp);
            numer = _mm256_mul_ps(numer,
                     _mm256_mul_ps(origx, origx));
            // denom update omitted here for brevity
            sign *= -1;
        }
        _mm256_store_ps(&result[i], value);
    }
}</code></pre>

            <div class="qa-container">
                <!-- Part A -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (a) How many <code>float</code> elements are processed simultaneously in each loop iteration? (1
                        mark)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>A <code>__m256</code> register holds 256 bits, so for 32â€‘bit <code>float</code>s it holds
                                8 elements; thus 8 elements are processed simultaneously per loop iteration.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„Ù€ Register (Ø§Ù„Ù…Ø®Ø²Ù†) Ø­Ø¬Ù…Ù‡ 256 Ø¨Øª. ÙˆØ§Ø­Ù†Ø§ Ø¹Ø§Ø±ÙÙŠÙ† Ø¥Ù† Ø§Ù„Ù€ float Ø§Ù„ÙˆØ§Ø­Ø¯ Ø¨ÙŠØ§Ø®Ø¯ 32 Ø¨Øª. Ù„Ùˆ Ù…Ø¹Ø§Ù„Ùƒ
                                "Ø£ØªÙˆØ¨ÙŠØ³" 256 ÙƒØ±Ø³ÙŠØŒ ÙˆØ§Ù„Ø±Ø§ÙƒØ¨ Ø¨ÙŠØ§Ø®Ø¯ 32ØŒ ÙŠØ¨Ù‚Ù‰ Ù‡ØªØ´ÙŠÙ„ ÙƒØ§Ù… Ø±Ø§ÙƒØ¨ØŸ Ø¨Ø§Ù„Ø¸Ø¨Ø·ØŒ 256 / 32 = 8 Ø£Ø±Ù‚Ø§Ù…
                                (floats).</p>
                        </div>
                    </div>
                </div>

                <!-- Part B -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (b) Explain the purpose of <code>_mm256_broadcast_ss</code> in this context. (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p><code>_mm256_broadcast_ss</code> takes a single scalar <code>float</code> and replicates
                                it into all 8 lanes of a <code>__m256</code> register so that the same scalar value
                                (e.g., 3! = 6) can be used in parallel operations on all vector elements without loading
                                it separately for each lane.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø¯Ø§Ù„Ø© <code>broadcast_ss</code> Ø¯ÙŠ Ø¨ØªÙˆÙØ± Ù…Ø¬Ù‡ÙˆØ¯. Ø¨Ø¯Ù„ Ù…Ø§ ØªØ­Ù…Ù„ Ø§Ù„Ø±Ù‚Ù… 6 Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© 8 Ù…Ø±Ø§ØªØŒ Ù‡ÙŠ
                                Ø¨ØªØ¬ÙŠØ¨Ù‡ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙˆØªØ¹Ù…Ù„Ù‡ "Copy-Paste" ÙÙŠ Ø§Ù„Ù€ 8 Ø®Ø§Ù†Ø§Øª Ø¨ØªÙˆØ¹ Ø§Ù„Ù€ Vector. ÙƒØ£Ù†Ùƒ Ø¨ØªÙ‚ÙˆÙ„ "ÙŠØ§
                                Ø¬Ù…Ø§Ø¹Ø©ØŒ ÙƒÙ„ÙƒÙ… Ù‡ØªØ¶Ø±Ø¨ÙˆØ§ ÙÙŠ 6".</p>
                        </div>
                    </div>
                </div>

                <!-- Part C -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (c) Why is 32-byte alignment important for arrays used with these AVX loads/stores? (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>AVX loads and stores are optimized when the memory address is 32â€‘byte aligned, which
                                avoids crossing cache-line boundaries, reduces the number of memory transactions, and
                                prevents potential penalties or faults that can occur with misaligned accesses; the
                                lecture highlights the use of <code>__declspec(align(32))</code> and custom aligned
                                allocation routines for this reason.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù€ Alignment Ø¯Ù‡ Ø²ÙŠ "Ø§Ù„Ø±ÙƒÙ†Ø© Ø§Ù„ØµØ­". Ø§Ù„Ù€ AVX Ø³Ø±ÙŠØ¹ Ø¬Ø¯Ø§Ù‹ Ø¨Ø³ Ø¨ÙŠØ­Ø¨ Ø§Ù„Ù†Ø¸Ø§Ù…. Ù„Ø§Ø²Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                                ØªØ¨Ø¯Ø£ Ù…Ù† Ø¹Ù†Ø§ÙˆÙŠÙ† Ø¨ØªÙ‚Ø¨Ù„ Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ 32 (Ù…Ø¶Ø§Ø¹ÙØ§Øª Ø§Ù„Ù€ 32). Ù„Ùˆ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª "Ù…Ø±Ø­Ù„Ø©" (misaligned)ØŒ
                                Ø§Ù„Ø¨Ø±ÙˆØ³ÙŠØ³ÙˆØ± Ù‡ÙŠØªØ¹Ø·Ù„ Ø¹Ø´Ø§Ù† ÙŠÙ„Ù…Ù‡Ø§ Ù…Ù† Ù‡Ù†Ø§ ÙˆÙ…Ù† Ù‡Ù†Ø§ØŒ ÙˆØ¯Ù‡ Ø¨ÙŠØ¶ÙŠØ¹ ÙˆÙ‚Øª.</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="reference small" style="margin-top: 20px;">
                ğŸ“ Reference: Lecture_5-and-6.pdf â€“ â€œVector program (using AVX intrinsics)â€, AVX intrinsic descriptions,
                and the alignment discussion with <code>__declspec(align(32))</code> and aligned malloc/free.
            </div>
        </div>
    </div>

    <!-- Q3 -->
    <!-- Q3 -->
    <div class="question">
        <div class="question-header">
            <span class="question-number">Question 3</span>
            <span class="question-marks">5 Marks</span>
        </div>
        <div class="question-content">
            <h3>Multiâ€‘Threading and Latency Hiding</h3>
            <p>
                You have a core with 8 SIMD ALUs executing a throughput-oriented workload. Each thread processes 8
                elements
                and then stalls for approximately 100 cycles waiting for data from memory.
            </p>

            <div class="qa-container">
                <!-- Part A -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (a) Explain how interleaving multiple threads on this core can hide memory latency. (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>Multiâ€‘threading hides latency by switching the core to execute instructions from other
                                runnable threads whenever one thread stalls on a longâ€‘latency memory access; while one
                                thread waits ~100 cycles for data to return, other threadsâ€™ instructions keep the ALUs
                                busy, similar to the diagrams where multiple threads are interleaved on a single core.
                            </p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ù„Ø¹Ø¨Ø© Ø§Ù„Ø§Ø³ØªØºÙ…Ø§ÙŠØ© Ù…Ø¹ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: Ø§Ù„ÙÙƒØ±Ø© ÙƒÙ„Ù‡Ø§ Ø¥Ù†Ù†Ø§ "Ù…Ù†ÙˆÙ‚ÙØ´ Ø§Ù„Ù…ÙƒÙ†". Ù„Ù…Ø§ Ù…Ø³Ø§Ø± (Thread) ÙŠØ­ØªØ§Ø¬ Ø­Ø§Ø¬Ø©
                                Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆÙŠØ¶Ø·Ø± ÙŠØ³ØªÙ†Ù‰ (Stall)ØŒ Ø§Ù„Ø¨Ø±ÙˆØ³ÙŠØ³ÙˆØ± Ù…Ø´ Ø¨ÙŠÙ‚Ø¹Ø¯ Ø­Ø§Ø·Ø· Ø¥ÙŠØ¯Ù‡ Ø¹Ù„Ù‰ Ø®Ø¯Ù‡. Ø¨ÙŠØ±ÙˆØ­ Ù‚Ø§Ù„Ø¨ ÙÙˆØ±Ø§Ù‹
                                Ø¹Ù„Ù‰ Ù…Ø³Ø§Ø± ØªØ§Ù†ÙŠ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø´ØºÙ„. ÙÙƒØ£Ù†Ù†Ø§ Ø¨Ù†Ù…Ù„Ù‰ Ø§Ù„ÙØ±Ø§ØºØ§Øª Ø¨Ø´ØºÙ„.</p>
                        </div>
                    </div>
                </div>

                <!-- Part B -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (b) Assuming each thread performs negligible computation compared to the 100-cycle stall,
                        approximately how many threads would you need to fully hide the latency on this core? (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>If each thread performs almost no computation but then stalls for about 100 cycles, you
                                need on the order of 100 independent threads so that, in each cycle while one thread is
                                stalled, another has ready work to issue; the lectureâ€™s fictitious multiâ€‘core and GPU
                                examples show many more execution contexts than ALUs (e.g., up to 48 warps per core on
                                GTX 480) to achieve this kind of latency hiding.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ù„Ùˆ Ø§Ù„ÙˆØ§Ø­Ø¯ Ø¨ÙŠØ¹Ø·Ù„ 100 Ø¯ÙˆØ±Ø©ØŒ ÙŠØ¨Ù‚Ù‰ Ù…Ø­ØªØ§Ø¬ÙŠÙ† Ø·Ø§Ø¨ÙˆØ± ÙÙŠÙ‡ 100 ÙˆØ§Ø­Ø¯ Ø¹Ø´Ø§Ù† Ù†ØºØ·ÙŠ Ø§Ù„ÙˆÙ‚Øª Ø¯Ù‡. ÙƒÙ„ Ù…Ø§ ÙˆØ§Ø­Ø¯
                                ÙŠØ¹Ø·Ù„ØŒ Ù†Ù„Ø§Ù‚ÙŠ ØºÙŠØ±Ù‡ Ø¬Ø§Ù‡Ø²ØŒ ÙˆÙ‡ÙƒØ°Ø§ Ù„Ø­Ø¯ Ù…Ø§ Ø§Ù„Ø£ÙˆÙ„Ø§Ù†ÙŠ ÙŠØ±Ø¬Ø¹Ù„Ù‡ Ø·Ù„Ø¨Ù‡.</p>
                        </div>
                    </div>
                </div>

                <!-- Part C -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (c) Discuss the trade-off between having many small thread contexts and a few large thread
                        contexts. (1 mark)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>Many small contexts improve latency hiding (more threads to schedule when others stall)
                                but require more storage for contexts and can increase working set size, reducing cache
                                effectiveness; fewer large contexts reduce context storage and may improve per-thread
                                locality but give the scheduler fewer options to hide latency, as illustrated by the
                                â€œmany small contexts (18 threads)â€ versus â€œfour large contextsâ€ examples.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„ÙØ±Ù‚ Ø¨Ø³ÙŠØ·: Ø³ÙŠØ§Ù‚Ø§Øª ØµØºÙŠØ±Ø© (Small Contexts) = "Ø¹ÙØ´ Ù‚Ù„ÙŠÙ„"ØŒ ÙÙ†Ù‚Ø¯Ø± Ù†Ø¬ÙŠØ¨ Ù…Ø³Ø§Ø±Ø§Øª ÙƒØªÙŠØ± Ø£ÙˆÙŠ ÙˆÙ†Ø®Ø¨ÙŠ
                                Ø§Ù„ØªØ£Ø®ÙŠØ± Ø¨Ø±Ø§Ø­ØªÙ†Ø§. Ø³ÙŠØ§Ù‚Ø§Øª ÙƒØ¨ÙŠØ±Ø© (Large Contexts) = "Ø¹ÙØ´ ÙƒØªÙŠØ±"ØŒ ÙØ§Ù„Ù…ÙƒØ§Ù† ÙŠØªØ²Ø­Ù… ÙˆÙ…Ù‚Ø¯Ø±Ø´ Ø£Ø´ØºÙ„
                                ØºÙŠØ± ÙƒØ§Ù… ÙˆØ§Ø­Ø¯ Ø¨Ø³ØŒ ÙˆÙ„Ùˆ ÙƒÙ„Ù‡Ù… Ø¹Ø·Ù„ÙˆØ§.. Ø§Ù„Ø¬Ù‡Ø§Ø² Ù‡ÙŠÙ‚Ù.</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="reference small" style="margin-top: 20px;">
                ğŸ“ Reference: Lecture_5-and-6.pdf â€“ â€œMulti-threading reduces Stallsâ€, â€œMany small contexts (high latency
                hiding ability)â€ and â€œFour large contexts (low latency hiding ability)â€, and the fictitious
                multi-core/GPU execution context slides.
            </div>
        </div>
    </div>

    <!-- Q4 -->
    <!-- Q4 -->
    <div class="question">
        <div class="question-header">
            <span class="question-number">Question 4</span>
            <span class="question-marks">5 Marks</span>
        </div>
        <div class="question-content">
            <h3>Thread Divergence and Conditional Execution</h3>
            <p>Consider the following per-element computation executed on an 8â€‘wide SIMD unit over an array
                <code>A</code>:
            </p>
            <pre><code>float x = A[i];
if (x &gt; 0) {
    float tmp = exp(x, 5.0f);
    tmp *= kMyConst1;
    x = tmp + kMyConst2;
} else {
    float tmp = kMyConst1;
    x = 2.0f * tmp;
}
result[i] = x;</code></pre>
            <p>
                Suppose for a particular 8-element group, the branch outcomes are <code>T T F T F F F F</code>.
            </p>

            <div class="qa-container">
                <!-- Part A -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (a) Define â€œdivergent executionâ€ and explain why it occurs in this case. (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>Divergent execution is a lack of instruction stream coherence where elements in a SIMD
                                group follow different control-flow paths; here, some elements (T) take the â€œifâ€ branch
                                and others (F) take the â€œelseâ€ branch, so the single shared instruction stream cannot
                                steer all 8 elements through the same instructions without executing both paths.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„ØªØ¨Ø§Ø¹Ø¯ Ø¯Ù‡ Ø²ÙŠ Ù…Ø§ ØªÙƒÙˆÙ† ÙØ±Ù‚Ø© Ù…Ø§Ø´ÙŠØ© Ù…Ø¹ Ø¨Ø¹Ø¶ØŒ ÙˆÙØ¬Ø£Ø© Ø·Ø±ÙŠÙ‚Ù‡Ù… Ø§ØªÙ‚Ø³Ù… Ù†ØµÙŠÙ†. Ø´ÙˆÙŠØ© Ø¹Ø§ÙŠØ²ÙŠÙ† ÙŠØ±ÙˆØ­ÙˆØ§ ÙŠÙ…ÙŠÙ†
                                ÙˆØ´ÙˆÙŠØ© Ø´Ù…Ø§Ù„. Ø¨Ø³ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø¥Ù†Ù‡Ù… Ù„Ø§Ø²Ù… ÙŠÙ…Ø´ÙˆØ§ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© Ù…Ø¹ Ø¨Ø¹Ø¶ (SIMD). ÙØ¨ÙŠØ­ØµÙ„ Ø¥Ù†Ù†Ø§ Ø¨Ù†Ù…Ø´ÙŠ Ù…Ø¹
                                Ø¨ØªÙˆØ¹ Ø§Ù„ÙŠÙ…ÙŠÙ† Ø§Ù„Ø£ÙˆÙ„ ÙˆØ§Ù„Ø¨Ø§Ù‚ÙŠ ÙˆØ§Ù‚Ù Ù…Ø³ØªÙ†ÙŠØŒ ÙˆØ¨Ø¹Ø¯ÙŠÙ† Ù†Ø±Ø¬Ø¹ Ù†Ù…Ø´ÙŠ Ù…Ø¹ Ø¨ØªÙˆØ¹ Ø§Ù„Ø´Ù…Ø§Ù„ ÙˆØ§Ù„Ø¨Ø§Ù‚ÙŠ ÙˆØ§Ù‚Ù. Ø¯Ù‡
                                Ø¨ÙŠØ¹Ø·Ù„ Ø§Ù„Ø¯Ù†ÙŠØ§.</p>
                        </div>
                    </div>
                </div>

                <!-- Part B -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (b) Qualitatively, what fraction of the SIMD ALUs are doing useful work during the if/else
                        region in the worst divergence case, according to the lecture? (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>In the worst divergence case described in the lecture, only 1 out of 8 SIMD lanes does
                                useful work on a given branch, so performance can drop to about <code>1/8</code> (12.5%)
                                of peak; with the <code>T T F T F F F F</code> mask, one branch uses 3/8 lanes and the
                                other 5/8 lanes, but the lecture explicitly notes the worst case as 1/8.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>ÙÙŠ Ø£Ø³ÙˆØ£ Ø§Ù„Ø¸Ø±ÙˆÙØŒ Ù„Ùˆ ÙƒÙ„ ÙˆØ§Ø­Ø¯ Ø¹Ø§ÙŠØ² ÙŠØ±ÙˆØ­ ÙÙŠ Ø³ÙƒØ© Ù„ÙˆØ­Ø¯Ù‡ØŒ Ø§Ù„ÙƒÙØ§Ø¡Ø© Ù…Ù…ÙƒÙ† ØªÙ†Ø²Ù„ Ù„Ù„Ø«Ù…Ù† (1/8). ÙŠØ¹Ù†ÙŠ
                                ÙˆØ§Ø­Ø¯ Ø¨Ø³ Ø§Ù„Ù„ÙŠ Ø´ØºØ§Ù„ ÙˆØ§Ù„Ù€ 7 Ø§Ù„Ø¨Ø§Ù‚ÙŠÙŠÙ† Ø¹Ø§Ø·Ù„ÙŠÙ† ÙÙŠ ÙƒÙ„ Ø®Ø·ÙˆØ©.</p>
                        </div>
                    </div>
                </div>

                <!-- Part C -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (c) Describe how masking is used to implement such divergent branches on SIMD hardware. (1 mark)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>SIMD hardware executes both branch bodies under different masks: when evaluating the â€œifâ€
                                body, a mask enables only lanes whose condition is true and suppresses writes for
                                others; then it executes the â€œelseâ€ body under the inverse mask, so only false lanes
                                update their results, after which execution reconverges with all lanes executing the
                                same instructions again.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„Ù‚Ù†Ø§Ø¹ (Masking) Ø¯Ù‡ Ø²ÙŠ "ÙƒØ§ØªÙ… Ø§Ù„ØµÙˆØª" Ø£Ùˆ Ø²Ø±Ø§Ø± Ø§Ù„ØªØ´ØºÙŠÙ„. Ù„Ù…Ø§ Ù†ÙƒÙˆÙ† Ø¨Ù†Ù†ÙØ° ÙƒÙˆØ¯ Ø§Ù„Ù€ ifØŒ Ø¨Ù†Ø­Ø· Ù‚Ù†Ø§Ø¹
                                ÙŠØ³Ù…Ø­ Ø¨Ø³ Ù„Ù„ÙŠ Ø§Ù„Ø´Ø±Ø· Ø¹Ù†Ø¯Ù‡Ù… ØªØ­Ù‚Ù‚ Ø¥Ù†Ù‡Ù… ÙŠÙƒØªØ¨ÙˆØ§ Ø§Ù„Ù†ØªØ§ÙŠØ¬ØŒ ÙˆØ§Ù„Ø¨Ø§Ù‚ÙŠ "ØµØ§Ù…Øª". ÙˆÙ„Ù…Ø§ Ù†Ø±ÙˆØ­ Ù„Ù„Ù€ elseØŒ
                                Ù†Ø¹ÙƒØ³ Ø§Ù„Ù‚Ù†Ø§Ø¹.</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="reference small" style="margin-top: 20px;">
                ğŸ“ Reference: Lecture_5-and-6.pdf â€“ â€œWhat about conditional execution?â€, â€œMask (discard) output of ALUâ€,
                â€œAfter branch: continue at full performanceâ€, and the â€œWorst case: 1/8 peak performanceâ€ note.
            </div>
        </div>
    </div>

    <div class="section-header">SECTION 2: THEORETICAL CONCEPTS (20 marks)</div>

    <!-- Q5 -->
    <!-- Q5 -->
    <div class="question">
        <div class="question-header">
            <span class="question-number">Question 5</span>
            <span class="question-marks">6 Marks</span>
        </div>
        <div class="question-content">
            <h3>Three Major Processor Ideas</h3>
            <p>The lecture summarizes three major ideas used by modern processors to exploit parallel execution.</p>

            <div class="qa-container">
                <!-- Part A -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (a) Explain the idea of using multiple cores (multiâ€‘core) and what kind of parallelism it
                        exploits. (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>The multiâ€‘core idea uses increasing transistor counts to add multiple simpler cores
                                rather than a single very complex core, providing threadâ€‘level parallelism where each
                                core executes its own instruction stream; software explicitly creates threads (e.g.,
                                with pthreads), and different cores can run different parts of the program concurrently.
                            </p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„Ù€ Multi-core: Ø¨Ø¯Ù„ "Ø³ÙˆØ¨Ø± Ù…Ø§Ù†" ÙˆØ§Ø­Ø¯ (Ù†ÙˆØ§Ø© Ù…Ø¹Ù‚Ø¯Ø©)ØŒ Ø¨Ù†Ø¬ÙŠØ¨ "ÙØ±ÙŠÙ‚ ÙƒÙˆØ±Ø©" (Ù†ÙˆÙ‰ Ø£Ø¨Ø³Ø·). ÙƒÙ„ Ù„Ø§Ø¹Ø¨
                                (Ù†ÙˆØ§Ø©) Ø¨ÙŠÙ…Ø³Ùƒ Ù…Ù„Ù Ø£Ùˆ Ø¨Ø±Ù†Ø§Ù…Ø¬ ÙŠØ®Ù„ØµÙ‡ Ù…Ø¹ Ù†ÙØ³Ù‡ (Thread-Level).</p>
                        </div>
                    </div>
                </div>

                <!-- Part B -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (b) Explain the idea of amortizing instruction stream cost over many ALUs (SIMD) and what kind
                        of parallelism it exploits. (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>The SIMD idea adds multiple ALUs under a single fetch/decode unit so that one instruction
                                stream operates on many data elements in parallel (dataâ€‘level parallelism); the cost and
                                complexity of instruction stream management is amortized across many ALUs, increasing
                                compute capability with relatively little extra control logic.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„Ù€ SIMD: Ø¯ÙŠ Ø³ÙŠØ§Ø³Ø© "Ø§Ø¶Ø±Ø¨ Ø¯Ø³ØªØ© Ø¹ØµØ§ÙÙŠØ± Ø¨Ø­Ø¬Ø±". Ø£Ù…Ø± ÙˆØ§Ø­Ø¯ Ø¨ÙŠØ·Ù„Ø¹ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ø¯ØŒ Ø¨ÙŠØªÙ†ÙØ° Ø¹Ù„Ù‰ 8 Ø£Ùˆ 16
                                Ø±Ù‚Ù… ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù„Ø­Ø¸Ø©. ØªÙˆÙÙŠØ± ÙÙŠ Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© ÙˆØªØ±ÙƒÙŠØ² ÙÙŠ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª.</p>
                        </div>
                    </div>
                </div>

                <!-- Part C -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (c) Explain the idea of multiâ€‘threading and how it improves utilization of processing resources.
                        (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>Multiâ€‘threading interleaves execution of many threads on the same core to hide long
                                latencies (especially memory); when one thread stalls, the core switches to another
                                runnable thread, filling otherwise idle cycles and making more efficient use of
                                superscalar and SIMD resources, at the cost of more context storage and potentially
                                higher perâ€‘thread latency.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„Ù€ Multi-threading: Ø¯ÙŠ "Ø®ÙØ© Ø§Ù„ÙŠØ¯". Ù„Ù…Ø§ Ù…Ø³Ø§Ø± ÙŠØ¹Ø·Ù„ØŒ Ø§Ù„ØªØ§Ù†ÙŠ ÙŠØ¯Ø®Ù„ Ù…ÙƒØ§Ù†Ù‡ ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù„Ø­Ø¸Ø©.
                                Ø§Ù„Ø¨Ø±ÙˆØ³ÙŠØ³ÙˆØ± (Core) Ù…Ø¨ÙŠÙ‚ÙØ´ØŒ Ø´ØºØ§Ù„ Ø§Ù„Ù„Ù‡ ÙŠÙ†ÙˆØ± 24 Ø³Ø§Ø¹Ø©.</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="reference small" style="margin-top: 20px;">
                ğŸ“ Reference: Lecture_5-and-6.pdf â€“ â€œCPU: Multi-Core Eraâ€, â€œAdd ALUs to increase compute capability
                (SIMD processing)â€, â€œMulti-threading reduces Stallsâ€, and the final â€œSummary: parallel executionâ€ slide.
            </div>
        </div>
    </div>

    <!-- Q6 -->
    <!-- Q6 -->
    <div class="question">
        <div class="question-header">
            <span class="question-number">Question 6</span>
            <span class="question-marks">5 Marks</span>
        </div>
        <div class="question-content">
            <h3>Memory Latency and Bandwidth</h3>

            <div class="qa-container">
                <!-- Part A -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (a) Define memory latency and give a typical example value from the lecture. (1 mark)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>Memory latency is the time from issuing a memory request (load or store) until it is
                                serviced by the memory system; the lecture gives a typical value of about 100 cycles or
                                100 ns for a main memory access.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† "Ø§Ù„Ø³Ø±Ø¹Ø©" Ùˆ "Ø§Ù„Ø²Ø­Ù…Ø©": Ø§Ù„Ù€ Latency (Ø§Ù„ØªØ£Ø®ÙŠØ±): Ø¯Ù‡ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù„ÙŠ Ø¨ØªØ³ØªÙ†Ø§Ù‡ Ø¹Ø´Ø§Ù† Ø·Ù„Ø¨Ùƒ
                                ÙŠÙˆØµÙ„. Ø²ÙŠ Ø§Ù„Ø¯ÙŠÙ„ÙŠÙØ±ÙŠ Ù„Ù…Ø§ ÙŠÙ‚ÙˆÙ„Ùƒ "Ù‚Ø¯Ø§Ù…ÙŠ Ø³Ø§Ø¹Ø©".</p>
                        </div>
                    </div>
                </div>

                <!-- Part B -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (b) Define memory bandwidth and give an example value for a modern CPU memory system from the
                        lecture. (1 mark)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>Memory bandwidth is the rate at which data can be delivered from the memory system to the
                                processor; for a typical CPU example, the lecture shows about 21 GB/s for a DDR3 DRAM
                                system attached to a multiâ€‘core CPU.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„Ù€ Bandwidth (Ø§Ù„Ø¹Ø±Ø¶): Ø¯ÙŠ ÙƒÙ…ÙŠØ© Ø§Ù„Ø¨Ø¶Ø§Ø¹Ø© Ø§Ù„Ù„ÙŠ Ø¨ØªØªØ­Ø±Ùƒ ÙÙŠ Ø§Ù„Ø´Ø§Ø±Ø¹ ÙÙŠ Ø§Ù„Ø«Ø§Ù†ÙŠØ©. ÙƒÙ„ Ù…Ø§ Ø§Ù„Ø´Ø§Ø±Ø¹
                                ÙŠÙˆØ³Ø¹ØŒ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ§Øª ØªØ²ÙŠØ¯.</p>
                        </div>
                    </div>
                </div>

                <!-- Part C -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (c) Distinguish between latency hiding and latency reduction techniques, using examples from the
                        lecture. (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>Latency reduction techniques aim to make each access intrinsically faster (e.g., caches
                                that keep data close to the core or higherâ€‘bandwidth memory), while latency hiding
                                techniques mask the delay by doing other useful work while waiting; prefetching and
                                multiâ€‘threading are described as latency hiding mechanisms that reduce stalls rather
                                than the underlying latency.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>ØªÙ‚Ù„ÙŠÙ„ (Reduction) vs Ø¥Ø®ÙØ§Ø¡ (Hiding): Ø§Ù„ØªÙ‚Ù„ÙŠÙ„: ÙŠØ¹Ù†ÙŠ ØªØ¬ÙŠØ¨ "Ù…ÙˆØªÙˆØ³ÙŠÙƒÙ„ Ø³Ø±ÙŠØ¹" Ø£Ùˆ ØªÙ‚Ø±Ø¨ Ø§Ù„Ù…Ø®Ø²Ù†
                                (Caches). Ø§Ù„Ø¥Ø®ÙØ§Ø¡: ÙŠØ¹Ù†ÙŠ ÙˆØ§Ù†Øª Ù…Ø³ØªÙ†ÙŠ Ø§Ù„Ø¯ÙŠÙ„ÙŠÙØ±ÙŠØŒ ØªÙ‚ÙˆÙ… ØªØ±ÙˆÙ‚ Ø§Ù„Ø´Ù‚Ø© (Multi-threading). Ø§Ù„ÙˆÙ‚Øª
                                Ù‡Ùˆ Ù‡ÙˆØŒ Ø¨Ø³ Ø£Ù†Øª Ù…Ù†Ø¬Ø²Øª Ø´ØºÙ„ ÙˆÙ…Ø­Ø³ÙŠØªØ´ Ø¨Ø§Ù„Ù…Ù„Ù„.</p>
                        </div>
                    </div>
                </div>

                <!-- Part D -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (d) Name two hardware techniques mentioned in the lecture that help hide or tolerate memory
                        latency. (1 mark)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>Two hardware techniques from the lecture are (1) prefetching, which speculatively brings
                                data into caches before it is needed, and (2) multiâ€‘threading, which switches to other
                                threads while one thread waits on a memory access.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¥Ø®ÙØ§Ø¡: Ø§Ù„Ù€ Prefetching (Ø§Ù„ØªÙˆÙ‚Ø¹) ÙˆØ§Ù„Ù€ Multi-threading (ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ).</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="reference small" style="margin-top: 20px;">
                ğŸ“ Reference: Lecture_5-and-6.pdf â€“ â€œTerminology â€“ Memory Latency / Memory Bandwidthâ€, â€œCaches Reduce
                Length Of Stallsâ€, â€œPrefetching reduces stalls (hides latency)â€, and â€œMulti-threading reduces Stallsâ€.
            </div>
        </div>
    </div>

    <!-- Q7 -->
    <!-- Q7 -->
    <div class="question">
        <div class="question-header">
            <span class="question-number">Question 7</span>
            <span class="question-marks">5 Marks</span>
        </div>
        <div class="question-content">
            <h3>Coherent vs Divergent Execution</h3>

            <div class="qa-container">
                <!-- Part A -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (a) Define â€œCoherent Executionâ€ (instruction stream coherence) and explain when it is necessary
                        for efficiency. (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>Coherent execution (instruction stream coherence) means that the same instruction
                                sequence applies to all elements being operated on simultaneously; it is necessary for
                                efficient SIMD operation because a single fetch/decode unit is shared by multiple ALUs,
                                so lack of coherence forces the hardware to serialize or mask off lanes, wasting SIMD
                                capacity.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„ØªÙ†Ø§ØºÙ… vs Ø§Ù„Ù‡Ø±Ø¬Ø©: Coherent (Ù…ØªÙ…Ø§Ø³Ùƒ): ÙŠØ¹Ù†ÙŠ ÙØ±Ù‚Ø© Ù…ÙˆØ³ÙŠÙ‚ÙŠØ© Ù…Ø§Ø´ÙŠØ© Ø¹Ù„Ù‰ Ù†ÙˆØªØ© ÙˆØ§Ø­Ø¯Ø©. Ø¶Ø±ÙˆØ±ÙŠ Ø¬Ø¯Ø§Ù‹
                                Ù„Ù„Ù€ SIMD Ø¹Ø´Ø§Ù† ÙÙŠ "Ù…Ø§ÙŠØ³ØªØ±Ùˆ" ÙˆØ§Ø­Ø¯ Ø¨ÙŠØ­Ø±Ùƒ Ø§Ù„ÙƒÙ„.</p>
                        </div>
                    </div>
                </div>

                <!-- Part B -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (b) Define â€œDivergent Executionâ€. (1 mark)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>Divergent execution is defined as a lack of instruction stream coherence, i.e., when
                                different elements within a SIMD group follow different control paths, such as when
                                branches take different directions for different data elements.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Divergent (Ù…ØªØ¨Ø§Ø¹Ø¯): ÙŠØ¹Ù†ÙŠ ÙƒÙ„ ÙˆØ§Ø­Ø¯ Ø¨ÙŠØ¹Ø²Ù Ø¨Ù…Ø²Ø§Ø¬Ù‡. Ø¯Ù‡ Ø¨ÙŠØ­ØµÙ„ Ù„Ù…Ø§ Ø§Ù„Ù€ If conditions ØªÙØ±Ù‚
                                Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø¹Ù† Ø¨Ø¹Ø¶.</p>
                        </div>
                    </div>
                </div>

                <!-- Part C -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (c) According to the lecture, is coherent execution more critical for SIMD parallelism or for
                        multi-core parallelism? Justify. (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>Coherent execution is more critical for SIMD than for multi-core, because in SIMD all
                                ALUs share one instruction stream and divergence reduces utilization (e.g., to 1/8 of
                                peak in the worst case), whereas in a multiâ€‘core system each core has its own
                                fetch/decode unit and can execute completely different instruction streams without loss
                                of efficiency.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„Ù€ Coherence Ø­ÙŠØ§Ø© Ø£Ùˆ Ù…ÙˆØª Ù„Ù„Ù€ SIMD. Ù„Ùˆ Ù…ÙÙŠØ´ ØªÙ†Ø§ØºÙ…ØŒ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¨ÙŠÙ‚Ø¹ (Ø²ÙŠ Ù…Ø§ Ø´ÙˆÙÙ†Ø§ 1/8). Ù„ÙƒÙ† Ø§Ù„Ù€
                                Multi-core Ù…Ø´ ÙØ§Ø±Ù‚ Ù…Ø¹Ø§Ù‡ØŒ ÙƒÙ„ Ù†ÙˆØ§Ø© "Ø¨Ø±Ù†Ø³" ÙÙŠ Ù†ÙØ³Ù‡Ø§ ÙˆÙ„ÙŠÙ‡Ø§ Ù…Ø§ÙŠØ³ØªØ±Ùˆ (Control Unit) Ø®Ø§Øµ Ø¨ÙŠÙ‡Ø§ØŒ
                                ÙÙ…Ø´ Ù…Ø­ØªØ§Ø¬Ø© ØªØ¨Øµ ÙÙŠ ÙˆØ±Ù‚Ø© ØºÙŠØ±Ù‡Ø§.</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="reference small" style="margin-top: 20px;">
                ğŸ“ Reference: Lecture_5-and-6.pdf â€“ â€œTerminologyâ€ slide defining â€œCoherent Executionâ€ and â€œDivergent
                Executionâ€ and noting that coherence is required for efficient SIMD but â€œis NOT necessary for efficient
                parallelization across coresâ€.
            </div>
        </div>
    </div>

    <!-- Q8 -->
    <!-- Q8 -->
    <div class="question">
        <div class="question-header">
            <span class="question-number">Question 8</span>
            <span class="question-marks">4 Marks</span>
        </div>
        <div class="question-content">
            <h3>Explicit vs Implicit SIMD</h3>

            <div class="qa-container">
                <!-- Part A -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (a) Distinguish between â€œExplicit SIMDâ€ on CPUs and â€œImplicit SIMDâ€ on GPUs as described in the
                        lecture. (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>Explicit SIMD refers to SIMD parallelization done at compile time where the compiler
                                emits vector instructions (e.g., AVX) and the programmer may use intrinsics or rely on
                                autoâ€‘vectorization; implicit SIMD on many GPUs runs N instances of a scalar program
                                together, with hardware mapping those instances to SIMD ALUs so the program binary
                                itself appears scalar.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„ÙˆØ§Ø¶Ø­ ÙˆØ§Ù„Ù…Ø³ØªØ®Ø¨ÙŠ: Explicit (ØµØ±ÙŠØ­): Ø¯Ù‡ Ø´ØºÙ„ Ø§Ù„Ù…Ø­ØªØ±ÙÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ù€ CPU. Ø£Ù†Øª Ø¨ØªÙƒØªØ¨ ÙƒÙˆØ¯ AVX Ø¨Ù†ÙØ³ÙƒØŒ
                                Ø²ÙŠ Ø§Ù„Ù„ÙŠ Ø¨ÙŠØ³ÙˆÙ‚ Ù…Ø§Ù†ÙŠÙˆØ§Ù„ØŒ Ù…ØªØ­ÙƒÙ… ÙÙŠ ÙƒÙ„ ØºÙŠØ§Ø±. Implicit (Ø¶Ù…Ù†ÙŠ): Ø¯Ù‡ Ø´ØºÙ„ Ø§Ù„Ù€ GPU. Ø£Ù†Øª Ø¨ØªÙƒØªØ¨ ÙƒÙˆØ¯
                                "Ø¹Ø§Ø¯ÙŠ" Ù„Ø¹Ù†ØµØ± ÙˆØ§Ø­Ø¯ØŒ ÙˆÙƒØ§Ø±Øª Ø§Ù„Ø´Ø§Ø´Ø© Ù‡Ùˆ Ø§Ù„Ù„ÙŠ Ø¨ÙŠØ¬Ù…Ø¹Ù‡Ù… ÙˆÙŠØ´ØºÙ„Ù‡Ù… Ø­Ø²Ù… (SIMD) Ù…Ø¹ Ù†ÙØ³Ù‡. Ø²ÙŠ
                                Ø§Ù„Ø£ØªÙˆÙ…Ø§ØªÙŠÙƒØŒ Ù…Ø±ÙŠØ­ ÙˆØ³Ø±ÙŠØ¹.</p>
                        </div>
                    </div>
                </div>

                <!-- Part B -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (b) Give one example of each and briefly state one advantage of each approach. (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>An explicit SIMD example is a C function using AVX intrinsics like
                                <code>_mm256_mul_ps</code> and <code>_mm256_add_ps</code>, with the advantage that the
                                programmer can see and control the exact vector operations; an implicit SIMD example is
                                a GPU kernel launched over many threads where the hardware groups threads (e.g., into
                                warps of width 16â€“32) and executes them in lockstep, with the advantage of a simpler
                                scalar programming model at the source level.
                            </p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„Ù…ÙŠØ²Ø©: Ø§Ù„ØµØ±ÙŠØ­ Ø¨ÙŠØ¯ÙŠÙƒ ØªØ­ÙƒÙ… ÙƒØ§Ù…Ù„ (Control). Ø§Ù„Ø¶Ù…Ù†ÙŠ Ø£Ø³Ù‡Ù„ Ø¨ÙƒØªÙŠØ± ÙÙŠ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© (Ease of Use) ÙˆÙ…Ø´
                                Ù„Ø§Ø²Ù… ØªÙƒÙˆÙ† Ø®Ø¨ÙŠØ± Ù‡Ø§Ø±Ø¯ÙˆÙŠØ±.</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="reference small" style="margin-top: 20px;">
                ğŸ“ Reference: Lecture_5-and-6.pdf â€“ â€œSIMD Execution on Modern CPUsâ€ (Explicit SIMD) and â€œSIMD execution
                on many modern GPUsâ€ (Implicit SIMD).
            </div>
        </div>
    </div>

    <div class="section-header">SECTION 3: COMPARISON &amp; ANALYSIS (8 marks)</div>

    <!-- Q9 -->
    <!-- Q9 -->
    <div class="question">
        <div class="question-header">
            <span class="question-number">Question 9</span>
            <span class="question-marks">4 Marks</span>
        </div>
        <div class="question-content">
            <h3>CPU vs GPU Memory Hierarchies</h3>
            <p>Compare the memory hierarchy of a multi-core CPU and a GPU as described in the lecture.</p>

            <div class="qa-container">
                <!-- Part A -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (a) Describe the main structural differences between the CPU and GPU memory hierarchies shown
                        (cache sizes and memory type/bandwidth). (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>The CPU diagram shows per-core L1 (32 KB) and L2 (256 KB) caches plus a large shared L3
                                (8 MB) connected to DDR3 DRAM at ~21 GB/s, whereas the GPU diagram shows relatively
                                small per-core scratchpad/L1 (64 KB), texture cache (12 KB), shared execution contexts
                                (128 KB), a smaller shared L2 (768 KB), and much higher-bandwidth GDDR5 memory (~177
                                GB/s).</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„ÙØ±Ù‚ ÙÙŠ Ø§Ù„ØªØµÙ…ÙŠÙ…: Ø§Ù„Ù€ CPU Ø¯ÙŠ "Ø¯Ù…Ø§Øº ÙƒØ¨ÙŠØ±Ø©" (L3 Cache Ø¶Ø®Ù… 8MB) Ø¨Ø³ Ø§Ù„Ø·Ø±ÙŠÙ‚ Ù„ÙŠÙ‡Ø§ Ø¶ÙŠÙ‚ (21
                                GB/s). Ø§Ù„Ù€ GPU Ø¯ÙŠ "Ø¹Ø¶Ù„Ø§Øª ÙƒØªÙŠØ±" Ø¨Ø³ Ø°Ø§ÙƒØ±ØªÙ‡Ø§ Ø§Ù„Ø´Ø®ØµÙŠØ© ØµØºÙŠØ±Ø© (L1 ÙØªØ§ÙÙŠØª) Ù„ÙƒÙ† Ø§Ù„Ø·Ø±ÙŠÙ‚ Ø§Ù„Ø³Ø±ÙŠØ¹
                                Ø¨ØªØ§Ø¹Ù‡Ø§ ÙˆØ§Ø³Ø¹ Ø¬Ø¯Ø§Ù‹ (177 GB/s).</p>
                        </div>
                    </div>
                </div>

                <!-- Part B -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (b) Explain how these differences reflect a latency-oriented design for CPUs versus a
                        throughput-oriented design for GPUs. (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>CPUs use big caches and modest bandwidth to reduce average latency to memory and rely
                                heavily on caches and prefetching to keep a few threads running fast, while GPUs use
                                many threads, small caches, and very high bandwidth, relying mainly on multiâ€‘threading
                                to hide latency and maximize overall throughput rather than minimizing individual access
                                latency.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„Ù€ CPU Ù…Ø¹Ù…ÙˆÙ„Ø© Ø¹Ø´Ø§Ù† "ØªÙ†Ø¬Ø²Ùƒ" (Latency Oriented)ØŒ ÙØ¨ØªØ­Ø· ÙƒØ§Ø´ ÙƒØ¨ÙŠØ± Ø¹Ø´Ø§Ù† Ù…ØªØ³ØªÙ†Ø§Ø´. Ø§Ù„Ù€ GPU
                                Ù…Ø¹Ù…ÙˆÙ„Ø© Ø¹Ø´Ø§Ù† "ØªÙØ±Ù…" (Throughput Oriented)ØŒ Ù…Ø´ Ù…Ù‡Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ÙˆØ§Ø­Ø¯Ø© ØªØ§Ø®Ø¯ ÙˆÙ‚Øª Ù‚Ø¯ Ø¥ÙŠÙ‡ØŒ Ø§Ù„Ù…Ù‡Ù…
                                Ø¥Ù† ÙÙŠ Ø§Ù„Ø¢Ø®Ø± Ø¨Ø·Ù„Ø¹ Ù…Ù„Ø§ÙŠÙŠÙ† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª ÙÙŠ Ù†ÙØ³ Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø¨Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø·Ø±ÙŠÙ‚ Ø§Ù„ÙˆØ§Ø³Ø¹ Ø¯Ù‡ ÙˆØ§Ù„Ù…Ø³Ø§Ø±Ø§Øª
                                Ø§Ù„ÙƒØªÙŠØ±.</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="reference small" style="margin-top: 20px;">
                ğŸ“ Reference: Lecture_5-and-6.pdf â€“ â€œCPU vs. GPU memory hierarchiesâ€ slide, including cache sizes and 21
                GB/s vs 177 GB/s bandwidth numbers.
            </div>
        </div>
    </div>

    <!-- Q10 -->
    <!-- Q10 -->
    <div class="question">
        <div class="question-header">
            <span class="question-number">Question 10</span>
            <span class="question-marks">4 Marks</span>
        </div>
        <div class="question-content">
            <h3>Bandwidth vs Computation and Arithmetic Intensity</h3>
            <p>The lecture considers the element-wise product <code>C[i] = A[i] * B[i]</code> on a NVIDIA GTX 480 GPU.
            </p>
            <p>Assume:</p>
            <ul>
                <li>Each element is a 32-bit float (4 bytes).</li>
                <li>For each <code>i</code>, you load <code>A[i]</code>, load <code>B[i]</code>, and store
                    <code>C[i]</code>.
                </li>
                <li>The GPU can perform 480 MULs per clock at 1.4 GHz, for a peak of about 1.345 TFLOPS with FMA.</li>
                <li>The memory bandwidth is about 177 GB/s.</li>
            </ul>

            <div class="qa-container">
                <!-- Part A -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (a) How many bytes are moved per element update (one multiply)? (1 mark)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>There are 3 memory operations per element: load <code>A[i]</code>, load
                                <code>B[i]</code>, and store <code>C[i]</code>, for a total of 3 Ã— 4 = 12 bytes per
                                multiply.
                            </p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø­Ø³Ø¨Ø© "ÙÙŠØ±Ø§Ø±ÙŠ ÙÙŠ Ø²Ø­Ù…Ø© Ø±Ù…Ø³ÙŠØ³": ÙƒÙ„ Ø¹Ù…Ù„ÙŠØ© Ø¶Ø±Ø¨ ÙŠØªÙŠÙ…Ø© Ù…Ø­ØªØ§Ø¬Ø© 3 Ù…Ø´Ø§ÙˆÙŠØ± Ù„Ù„Ø°Ø§ÙƒØ±Ø©: Ù†Ø¬ÙŠØ¨ A Ùˆ B ÙˆÙ†Ø®Ø²Ù†
                                C. ÙƒÙ„ ÙˆØ§Ø­Ø¯ 4 Ø¨Ø§ÙŠØªØŒ ÙŠØ¹Ù†ÙŠ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ 12 Ø¨Ø§ÙŠØª Ù†Ù‚Ù„ Ù„ÙƒÙ„ Ø¹Ù…Ù„ÙŠØ© Ø¶Ø±Ø¨ ÙˆØ§Ø­Ø¯Ø©.</p>
                        </div>
                    </div>
                </div>

                <!-- Part B -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (b) Roughly how much bandwidth would be required to sustain peak compute performance on this
                        operation, according to the lecture? (1 mark)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>The lecture notes that to keep the functional units fully busy on this pattern, the
                                system would need on the order of 8 TB/s of memory bandwidth, far above the available
                                177 GB/s.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø¹Ø´Ø§Ù† Ù†Ø´ØºÙ„ Ø§Ù„ÙƒØ§Ø±Øª Ø¯Ù‡ Ø¨Ø·Ø§Ù‚ØªÙ‡ Ø§Ù„Ù‚ØµÙˆÙ‰ (Peak Compute)ØŒ Ù…Ø­ØªØ§Ø¬ÙŠÙ† Ø·Ø±ÙŠÙ‚ ÙŠÙ†Ù‚Ù„ 8000 Ø¬ÙŠØ¬Ø§Ø¨Ø§ÙŠØª ÙÙŠ
                                Ø§Ù„Ø«Ø§Ù†ÙŠØ© (8 TB/s).</p>
                        </div>
                    </div>
                </div>

                <!-- Part C -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (c) What approximate efficiency (fraction of peak) does the lecture state is achievable given
                        177 GB/s? (1 mark)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>With only 177 GB/s available versus the 8 TB/s requirement, the lecture estimates that
                                the achievable efficiency is about 2% of peak compute performance on this operation.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø¨Ø³ Ø¥Ø­Ù†Ø§ ØºÙ„Ø§Ø¨Ø© ÙˆÙ…Ø¹Ø§Ù†Ø§ 177 GB/s Ø¨Ø³. ÙŠØ¹Ù†ÙŠ Ù…Ø¹Ø§Ù†Ø§ Ø­ÙˆØ§Ù„ÙŠ 2% Ø¨Ø³ Ù…Ù† Ø§Ù„Ø³Ø±Ø¹Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©. Ø§Ù„ÙƒØ§Ø±Øª Ù‚Ø§Ø¹Ø¯
                                ÙØ§Ø¶ÙŠ 98% Ù…Ù† Ø§Ù„ÙˆÙ‚Øª Ù…Ø³ØªÙ†ÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªÙŠØ¬ÙŠ.</p>
                        </div>
                    </div>
                </div>

                <!-- Part D -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (d) Define â€œArithmetic Intensityâ€ and explain why this vector multiply is bandwidth-bound. (1
                        mark)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p>Arithmetic Intensity is the ratio of math operations to data access operations (or FLOPs
                                per byte); this vector multiply has very low arithmetic intensityâ€”only one multiply per
                                12 bytesâ€”so performance is limited by memory bandwidth rather than compute capability,
                                making it bandwidth-bound.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p>Ø§Ù„ÙƒØ«Ø§ÙØ© Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠØ© (Arithmetic Intensity) ÙˆØ§Ø·ÙŠØ© Ø¬Ø¯Ø§Ù‹ Ù‡Ù†Ø§. Ø¨Ù†Ù†Ù‚Ù„ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØªÙŠØ± (12 Ø¨Ø§ÙŠØª) Ø¹Ø´Ø§Ù†
                                Ù†Ø¹Ù…Ù„ Ø¹Ù…Ù„ÙŠØ© ÙˆØ§Ø­Ø¯Ø© ÙŠØªÙŠÙ…Ø©. ÙØ¹Ù†Ù‚ Ø§Ù„Ø²Ø¬Ø§Ø¬Ø© Ù‡Ù†Ø§ Ù‡Ùˆ Ø§Ù„Ù€ Bandwidth Ù…Ø´ Ø³Ø±Ø¹Ø© Ø§Ù„Ø­Ø³Ø§Ø¨.</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="reference small" style="margin-top: 20px;">
                ğŸ“ Reference: Lecture_5-and-6.pdf â€“ â€œThought experimentâ€ and â€œBandwidth Limited!â€ slides, including the
                12 bytes per MUL, ~8 TB/s requirement, and ~2% efficiency discussion, and the â€œArithmetic Intensityâ€
                definition.
            </div>
        </div>
    </div>

    <div class="section-header">SECTION 4: CODE VERIFICATION (2 marks)</div>

    <!-- Q11 -->
    <!-- Q11 -->
    <div class="question">
        <div class="question-header">
            <span class="question-number">Question 11</span>
            <span class="question-marks">2 Marks</span>
        </div>
        <div class="question-content">
            <h3>True/False Code and Concept Verification</h3>

            <div class="qa-container">
                <!-- Part A -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (a) In a 1D CUDA kernel, the following code is used to compute a global thread index:<br />
                        <code>int idx = threadIdx.x + blockIdx.x * blockDim.x;</code><br />
                        State whether this is correct and justify your answer. (2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p><strong>Answer:</strong> This expression is correct for computing the 1D global thread
                                index in CUDA; it multiplies the block index by the number of threads per block to get
                                the starting index for the block and then adds the threadâ€™s index within the block,
                                yielding a unique global index for each thread in a 1D grid.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p><strong>ØµØ­ Ø§Ù„ØµØ­:</strong> Ø¯ÙŠ Ù…Ø¹Ø§Ø¯Ù„Ø© "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†" ÙÙŠ CUDA. Ø§Ù„Ù€
                                <code>blockIdx.x * blockDim.x</code> Ø¨ØªÙˆØµÙ„Ùƒ Ù„Ø£ÙˆÙ„ Ø§Ù„Ø´Ø§Ø±Ø¹ (Ø§Ù„Ø¨Ù„ÙˆÙƒ)ØŒ ÙˆØ§Ù„Ù€
                                <code>threadIdx.x</code> Ø¨ØªÙˆØµÙ„Ùƒ Ù„Ø±Ù‚Ù… Ø§Ù„Ø¨ÙŠØª (Ø§Ù„Ù…Ø³Ø§Ø± ) Ø¬ÙˆÙ‡ Ø§Ù„Ø´Ø§Ø±Ø¹ Ø¯Ù‡. ÙØ§Ù„Ù…Ø¬Ù…ÙˆØ¹ ÙŠØ¯ÙŠÙƒ
                                Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙØ±ÙŠØ¯ Ù„ÙƒÙ„ Ù…Ø³Ø§Ø± ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ© ÙƒÙ„Ù‡Ø§ (Grid).
                            </p>
                        </div>
                    </div>
                </div>

                <!-- Part B (Bonus) -->
                <div class="qa-pair">
                    <div class="qa-question">
                        (b) <span class="small">(Bonus)</span> â€œPrefetching and multi-threading are both latency
                        reduction techniques that directly decrease the time required to complete a memory access.â€
                        State whether this sentence is true or false and justify. (Bonus 2 marks)
                    </div>
                    <div class="qa-answer-block">
                        <div class="qa-english">
                            <div class="label-eng">ANSWER</div>
                            <p><strong>Answer:</strong> The statement is false; the lecture explicitly classifies
                                prefetching and multiâ€‘threading as latency <em>hiding</em>, not latency reducing,
                                techniquesâ€”they do not shorten the intrinsic memory access time, but instead reduce
                                stalls by overlapping memory accesses with other useful work.</p>
                        </div>
                        <div class="qa-arabic">
                            <div class="label-ar"> </div>
                            <p><strong>ØºÙ„Ø· Ø·Ø¨Ø¹Ø§Ù‹:</strong> Ø¯ÙˆÙ„ Ø§Ø³Ù…Ù‡Ù… "Ù…Ø³ÙƒÙ†Ø§Øª" (Hiding) Ù…Ø´ "Ø¹Ù„Ø§Ø¬" (Using). Ù‡Ù…Ø§ Ù…Ø´ Ø¨ÙŠØ³Ø±Ø¹ÙˆØ§
                                Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù†ÙØ³Ù‡Ø§ (Ø§Ù„Ù€ Latency Ø«Ø§Ø¨Øª)ØŒ Ù‡Ù…Ø§ Ø¨Ø³ Ø¨ÙŠØ®Ù„ÙˆÙƒ "ØªØªØ³Ù„Ù‰" ÙÙŠ Ø´ØºÙ„ ØªØ§Ù†ÙŠ Ø¹Ù‚Ø¨Ø§Ù„ Ù…Ø§ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                                ØªÙˆØµÙ„ØŒ ÙÙ…ØªØ­Ø³Ø´ Ø¨Ø§Ù„Ù…Ù„Ù„ (Stalls). Ø§Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ (Reduction) Ø¨ÙŠÙƒÙˆÙ† Ø¨Ø§Ù„Ù€ Caches.</p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="reference small" style="margin-top: 20px;">
                ğŸ“ Reference: Lecture_5-and-6.pdf â€“ CUDA/threading concepts and â€œPrefetching reduces stalls (hides
                latency)â€ discussion.
            </div>
        </div>
    </div>

    <h2>END OF EXAM</h2>
    <p class="small">
        All questions and answers are based solely on the content of Lecture_5-and-6.pdf (Parallel Execution and Memory
        Systems). No external material has been used.[file:2]
    </p>

</body>

</html>